{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install npTDMS\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from nptdms import TdmsFile\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### For JC data\n",
    "# folder = 'C:/Users/huynh/INT/karthala/data/2022_12_02P8_jedi_JC_best/points/points0008_best'\n",
    "# file = 'points0008_pmt1.tdms'\n",
    "\n",
    "### For Alberto's data\n",
    "# folder = 'C:/Users/huynh/INT/karthala/data/23_07_10_alberto/points/points0005_2023_07_10'\n",
    "# file = '2023_07_10_points0005_pmt1.tdms'\n",
    "\n",
    "### For Nicolais data\n",
    "folder = 'C:/Users/huynh/INT/karthala/data/GEVI_trace_Force1a/points0012'\n",
    "file = 'points0012_pmt1.tdms'\n",
    "\n",
    "path = os.path.join(folder, file)\n",
    "tdms_file = TdmsFile.read(path)\n",
    "\n",
    "parameter_group = tdms_file['parameter']\n",
    "print(\"parameter_group: \", parameter_group)\n",
    "\n",
    "name_channel = parameter_group['parameter']\n",
    "print(\"name_channel: \", name_channel)\n",
    "\n",
    "num_channel = parameter_group['value']\n",
    "print(\"num_channel: \", num_channel)\n",
    "\n",
    "name = name_channel[:]\n",
    "print(\"name: \", name)\n",
    "\n",
    "num = num_channel[:]\n",
    "print(\"num: \", num)\n",
    "\n",
    "parameter = np.vstack((name, num))\n",
    "print(\"parameter: \", parameter) \n",
    "\n",
    "numpoint = int(num[8]) # 8 is the array representing the number of points\n",
    "print(\"numpoint: \", numpoint)\n",
    "\n",
    "### NOTES:\n",
    "# timing: µs for one ROI, including delay of 10µs\n",
    "# nbr of points: # of ROIS\n",
    "# number of samples:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### EXTRACT SIGNAL AND METADATA FROM TDMS FILE\n",
    "time = tdms_file['PMT1']['POI time'].data/1000\n",
    "\n",
    "roi = []\n",
    "# Loading all data points\n",
    "for n in range(numpoint):\n",
    "    roi.append(tdms_file['PMT1']['POI ' + str(n) + ' '].data)\n",
    "\n",
    "roi = np.array(roi, dtype=float)  # Convert roi to double\n",
    "secperframe = time[1]\n",
    "framespersec = 1/secperframe\n",
    "print(\"secperframe: \", secperframe)\n",
    "\n",
    "print(\"framespersec: \", 1 / secperframe, 'Hz')\n",
    "\n",
    "# timemax = f\"{max(time)} seconds\"\n",
    "timemax = max(time)\n",
    "print(\"duration (s): \", timemax)\n",
    "\n",
    "print('original roi count: ', roi.shape[0])\n",
    "print('original roi length: ', roi.shape[1])\n",
    "print('original roi signal: ', roi)\n",
    "\n",
    "### COMBINE TWO POINTS (ONE CELL)\n",
    "roi_combined = []\n",
    "\n",
    "# Add signals for points 1 and 3, 2 and 4\n",
    "# roi[0] = roi[0] + roi[1] # 0 and 1 for JC.  this is an element-wise addition; this doubles the amplitude of the signal\n",
    "# roi_combined = roi[0] + roi[1] # 2 and 3 for alberto.  This is an element-wise addition; this doubles the amplitude of the signal\n",
    "\n",
    "roi_combined = roi[0] + roi[1] + roi[2] + roi[3] + roi[4] # all 5 for Nicolais.  0 and 1 have worse SNR, but still better all 5 than removing 0 and 1.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "### Loop through each array and add it as a separate trace\n",
    "for i in range(numpoint):\n",
    "    array = roi[i]\n",
    "    fig.add_trace(go.Scatter(y=array, mode='lines', name=f'Array {i+1}'))\n",
    "\n",
    "fig.add_trace(go.Scatter(y=roi_combined, mode='lines', name='roi_combined'))\n",
    "fig.add_trace(go.Scatter(y=roi_combined_234, mode='lines', name='roi_combined'))\n",
    "fig.add_trace(go.Scatter(y=roi_combined_01234, mode='lines', name='roi_combined'))\n",
    "\n",
    "\n",
    "# Update layout with appropriate title and labels\n",
    "fig.update_layout(\n",
    "    title=\"ROIS separated and combined\",\n",
    "    xaxis_title=\"Index\",\n",
    "    yaxis_title=\"Value\"\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### COMBINE TWO POINTS (ONE CELL)\n",
    "roi = []\n",
    "roi = roi_combined.copy() # negate for Jedi, but NOT for FORCE1A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the FFT\n",
    "fft_result = np.fft.fft(roi_butterfilt_zscore_gaussian)\n",
    "freqs = np.fft.fftfreq(len(fft_result), 1 / framespersec)  # Frequency bins\n",
    "\n",
    "# Plot the magnitude spectrum\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(freqs[:len(freqs)//2], np.abs(fft_result)[:len(freqs)//2])  # Plot only positive frequencies\n",
    "plt.xlabel('Frequency (Hz)')\n",
    "plt.ylabel('Magnitude')\n",
    "plt.title('Magnitude Spectrum of the Signal')\n",
    "plt.grid(True)\n",
    "plt.yscale('log')  # Set y-axis to logarithmic scale\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import signal\n",
    "from scipy.signal import savgol_filter\n",
    "import numpy as np\n",
    "from scipy.signal import butter, filtfilt\n",
    "\n",
    "\n",
    "def median_normalization(traces):\n",
    "    median_values = np.median(traces, axis=1, keepdims=True)\n",
    "    return traces / median_values\n",
    "\n",
    "def detrend_polyfit(traces, deg=15):\n",
    "    n_frames = len(traces)\n",
    "    time_vector = np.arange(n_frames)\n",
    "    p0 = np.polyfit(time_vector, traces.T, deg)\n",
    "    baseline = np.polyval(p0.T, time_vector)\n",
    "    return traces - baseline, baseline\n",
    "\n",
    "def zscore_normalization(traces):\n",
    "    mean_traces = np.mean(traces, keepdims=True)\n",
    "    std_traces = np.std(traces, keepdims=True)\n",
    "    return (traces - mean_traces) / std_traces\n",
    "\n",
    "def butter_lowpass_filter(data, cutoff_frequency, sampling_rate, order=4):\n",
    "    nyquist = 0.5 * sampling_rate\n",
    "    normal_cutoff = cutoff_frequency / nyquist\n",
    "    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
    "    lowpass_filtered_data = filtfilt(b, a, data)\n",
    "    return lowpass_filtered_data\n",
    "\n",
    "def baseline_removal_butterworth(signal, cutoff_frequency, sampling_rate, order=4):\n",
    "    # Apply a low-pass Butterworth filter to estimate baseline\n",
    "    baseline_estimate = butter_lowpass_filter(signal, cutoff_frequency, sampling_rate, order)\n",
    "    baseline_removed_signal = signal - baseline_estimate    \n",
    "    return baseline_removed_signal\n",
    "\n",
    "def sec_to_frame (time_in_sec):\n",
    "    return int(time_in_sec*framespersec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TESTING BUTTERWORTH METHOD:  from .2 to 20.  \n",
    "### Conclusion:  higher cutoff = smoother baseline, but also lower amplitude.\n",
    "### Choosing 0.5 because it's the lowest while removing the large baseline drifts\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "signal = roi.copy()\n",
    "order = 1\n",
    "cutoff_frequency = .2  # .2 best so far.  Also tried 10; the higher the freq, the smoother the baseline but small the amplitude.    \n",
    "\n",
    "roi_butterfilt = baseline_removal_butterworth(signal, cutoff_frequency, sampling_rate=framespersec)\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "# Compare different cut-off frequencies, select the lowest one that removes drift\n",
    "# fig.add_trace(go.Scatter(y=signal, mode='lines', name='raw'))\n",
    "fig.add_trace(go.Scatter(y=baseline_removal_butterworth(signal, cutoff_frequency = .2, sampling_rate=framespersec), mode='lines', name='.2'))\n",
    "fig.add_trace(go.Scatter(y=baseline_removal_butterworth(signal, cutoff_frequency = .5, sampling_rate=framespersec), mode='lines', name='.5'))\n",
    "fig.add_trace(go.Scatter(y=baseline_removal_butterworth(signal, cutoff_frequency = 10, sampling_rate=framespersec), mode='lines', name='10'))\n",
    "fig.add_trace(go.Scatter(y=baseline_removal_butterworth(signal, cutoff_frequency = 20, sampling_rate=framespersec), mode='lines', name='20')) # suggestion from Villette paper\n",
    "\n",
    "\n",
    "# Show the plot\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### COMPARING DETRENDING METHODS:  POLY FIT vs BUTTERWORTH.  \n",
    "### CONCLUSION:  SIMILAR, so go with Villette method (butterworth).  However, cutoff at .5 rather than .2  \n",
    "\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "roi_detrend = detrend_polyfit(roi.copy(),deg = 15)\n",
    "roi_detrend_zscore = zscore_normalization(roi_detrend[0].copy())\n",
    "\n",
    "# Convert x axis from frames to seconds\n",
    "x_values = [i * secperframe for i in range(len(roi))]\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "# fig.add_trace(go.Scatter(x=x_values, y=roi, mode='lines', name='original'))\n",
    "# fig.add_trace(go.Scatter(x=x_values, y=roi_detrend[1], mode='lines', name='detrend line'))\n",
    "# fig.add_trace(go.Scatter(x=x_values, y=roi_detrend[0], mode='lines', name='detrend'))\n",
    "fig.add_trace(go.Scatter(x=x_values, y=zscore_normalization(roi_detrend[0].copy()), mode='lines', name='detrend + zscore'))\n",
    "fig.add_trace(go.Scatter(x=x_values, y=zscore_normalization(roi_butterfilt.copy()), mode='lines', name='butterfilt + zscore'))\n",
    "\n",
    "\n",
    "fig.update_layout(\n",
    "    xaxis_title='Time (sec)',\n",
    "    yaxis_title='Amplitude'\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "\n",
    "roi_detrend = roi_detrend[0] # remove traces to make it easier to work with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ADDING ZSCORE NORMALIZATION \n",
    "import plotly.graph_objects as go\n",
    "\n",
    "order = 1 # lower order = less complex curvature but more authentic\n",
    "cutoff_frequency = .2  # .2 best so far.  Also tried 10; the higher the freq, the smoother the baseline but small the amplitude.    \n",
    "\n",
    "roi_butterfilt = baseline_removal_butterworth(roi.copy(), cutoff_frequency, sampling_rate=framespersec)\n",
    "roi_butterfilt_zscore = zscore_normalization(roi_butterfilt.copy())\n",
    "\n",
    "# Convert x axis from frames to seconds\n",
    "x_values = [i * secperframe for i in range(len(roi))]\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(x=x_values, y=roi, mode='lines', name='original'))\n",
    "fig.add_trace(go.Scatter(x=x_values, y=roi_butterfilt, mode='lines', name='butterfilt'))\n",
    "fig.add_trace(go.Scatter(x=x_values, y=roi_butterfilt_zscore, mode='lines', name='butterfilt + zscore'))\n",
    "\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Signal butterworth filtered and zscore normalized',\n",
    "    xaxis_title='Time (sec)',\n",
    "    yaxis_title='Amplitude'\n",
    ")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### COMPARE GAUSSIAN (and kernel sizes) TO SAVITZ GOLAY\n",
    "### Conclusion:  they look similar, so let's go with Villette method (Gaussian)    \n",
    "### However, kernel of 0.2 ms (from paper) has been raised (per Phan's opinion) \n",
    "\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "\n",
    "signal = roi_butterfilt_zscore.copy()\n",
    "framespersec\n",
    "kernel_sec = 0.005 # raised to 0.005 (sigma = 10.6) from 0.0002 (sigma = .4) because it looks better \n",
    "sigma = kernel_sec * framespersec / (2 * (2 * np.log(2))**0.5)\n",
    "roi_butterfilt_zscore_gaussian = gaussian_filter1d(signal.copy(), sigma = 10)\n",
    "\n",
    "roi_butterfilt_zscore_savgol = savgol_filter(signal.copy(), window_length = 25, polyorder = 6)\n",
    "\n",
    "# Convert x axis from frames to seconds\n",
    "x_values = [i * secperframe for i in range(len(roi))]\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "# fig.add_trace(go.Scatter(x=x_values, y=roi_butterfilt_zscore.copy(), mode='lines', name='roi_butterfilt_zscore'))\n",
    "fig.add_trace(go.Scatter(x=x_values, y=gaussian_filter1d(signal.copy(), sigma = .5), mode='lines', name='.5'))\n",
    "fig.add_trace(go.Scatter(x=x_values, y=gaussian_filter1d(signal.copy(), sigma = 2), mode='lines', name='2'))\n",
    "fig.add_trace(go.Scatter(x=x_values, y=gaussian_filter1d(signal.copy(), sigma = 5), mode='lines', name='5'))\n",
    "fig.add_trace(go.Scatter(x=x_values, y=gaussian_filter1d(signal.copy(), sigma = 10), mode='lines', name='10'))\n",
    "fig.add_trace(go.Scatter(x=x_values, y=gaussian_filter1d(signal.copy(), sigma = 20), mode='lines', name='5'))\n",
    "\n",
    "fig.add_trace(go.Scatter(x=x_values, y=roi_butterfilt_zscore_savgol, mode='lines', name='roi_butterfilt_zscore_savgol'))\n",
    "\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Comparing Gaussian to SavitzGolay smoothing',\n",
    "    xaxis_title='Time (sec)',\n",
    "    yaxis_title='Amplitude'\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ADDING GAUSSIAN SMOOTHING\n",
    "\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "\n",
    "signal = roi_butterfilt_zscore.copy()\n",
    "kernel_sec = 0.0005 # Villette paper used 0.0002 (sigma = .4), but I increased to 0.005 (sigma = 10.6) for easier analysis\n",
    "sigma = kernel_sec * framespersec / (2 * (2 * np.log(2))**0.5)\n",
    "\n",
    "roi_butterfilt_zscore_gaussian = gaussian_filter1d(signal.copy(), sigma)\n",
    "roi_butterfilt_zscore_gaussian_0002 = gaussian_filter1d(signal.copy(), sigma=0.42466) # 0.42466 is based on kernel_sec = .0002, from Villette paper\n",
    "\n",
    "# Convert x axis from frames to seconds\n",
    "x_values = [i * secperframe for i in range(len(roi))]\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(x=x_values, y=signal.copy(), mode='lines', name='Before smoothing'))\n",
    "fig.add_trace(go.Scatter(x=x_values, y=roi_butterfilt_zscore_gaussian, mode='lines', name='Gaussian Smoothing'))\n",
    "fig.add_trace(go.Scatter(x=x_values, y=roi_butterfilt_zscore_gaussian_0002, mode='lines', name='Gaussian Smoothing (.0002s)'))\n",
    "\n",
    "\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Adding Gaussian smoothing to butterfilter and zscore',\n",
    "    xaxis_title='Time (sec)',\n",
    "    yaxis_title='Amplitude'\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### FIND PEAKS roi_butterfilt_zscore_gaussian, Villette zscores and then thresholds at 4 std\n",
    "\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "def calculate_moving_average(trace, window_sec=0.5):\n",
    "    # Calculate the moving average\n",
    "    window_frames = int(window_sec * framespersec)\n",
    "    moving_avg = np.convolve(trace, np.ones(window_frames)/window_frames, mode='same')\n",
    "    return moving_avg\n",
    "\n",
    "def find_peaks_zscore(trace, window_sec=0.5, z_threshold=4, distance=100):\n",
    "    # Calculate the standard deviation\n",
    "    moving_std = np.std(trace)\n",
    "    moving_avg = calculate_moving_average(trace,window_sec)\n",
    "    # Find peaks based on 4 standard deviations over the moving average\n",
    "    threshold = z_threshold * moving_std\n",
    "    peaks, _ = find_peaks(trace, height=moving_avg + threshold, distance=distance)\n",
    "    # peaks = [i for i in range(len(trace)) if trace[i] > moving_avg[i] + threshold]\n",
    "    return peaks\n",
    "\n",
    "\n",
    "\n",
    "signal = roi_butterfilt_zscore_gaussian.copy()\n",
    "# signal = roi_butterfilt.copy() # For Nikolai, zscore and gaussian seemed unnecessary\n",
    "\n",
    "z_threshold = 5 # 5 for Alberto, 4 for JC\n",
    "window_sec=0.5\n",
    "peaks_found = find_peaks_zscore(signal.copy(),window_sec,z_threshold) \n",
    "\n",
    "print(\"peaks count: \", len(peaks_found))\n",
    "print(\"spikes / sec: \", len(peaks_found)/timemax)\n",
    "\n",
    "\n",
    "# Create Plotly figure\n",
    "fig = go.Figure()\n",
    "\n",
    "# Convert x axis from frames to seconds\n",
    "x_values = [i * secperframe for i in range(len(roi))]\n",
    "\n",
    "# Plot the trace\n",
    "# fig.add_trace(go.Scatter(x=x_values, y=roi, mode='lines', name='roi'))\n",
    "fig.add_trace(go.Scatter(x=x_values, y=signal, mode='lines', name='roi_butterfilt_zscore_gaussian'))\n",
    "fig.add_trace(go.Scatter(x=x_values, y=calculate_moving_average(signal), mode='lines', name='moving_avg'))\n",
    "\n",
    "\n",
    "### IDENTIFY an isolated spike for MLspike autocalibration [didn't work]\n",
    "iso_start_sec = 160  # Example value, you should specify your desired start x value\n",
    "iso_end_sec = 170   # Example value, you should specify your desired end y value\n",
    "print(\"iso_start_frame: \", sec_to_frame(iso_start_sec))\n",
    "print(\"iso_end_frame: \", sec_to_frame(iso_end_sec))\n",
    "# Create a trace for the highlighted segment\n",
    "iso_x = x_values[sec_to_frame(iso_start_sec):sec_to_frame(iso_end_sec)]\n",
    "iso_y = signal[sec_to_frame(iso_start_sec):sec_to_frame(iso_end_sec)]\n",
    "fig.add_trace(go.Scatter(x=iso_x, y=iso_y, mode='lines', name='isolated spike'))\n",
    "\n",
    "# Mark the peaks\n",
    "peaks_x = [x_values[i] for i in peaks_found]\n",
    "peaks_y = [signal[i] for i in peaks_found]\n",
    "fig.add_trace(go.Scatter(x=peaks_x, y=peaks_y, mode='markers', name='Peaks', marker=dict(color='red', size=8)))\n",
    "\n",
    "print(\"avg amplitude: \", np.average(peaks_y)) \n",
    "print(\"noise level (std / A): \", np.std(signal)/np.average(peaks_y)) # slightly over overestimated given that amplitudes were not removed from calculation\n",
    "\n",
    "# Add titles and labels\n",
    "fig.update_layout(\n",
    "    title=\"Peaks Detected from roi_butterfilt_zscore_gaussian\",\n",
    "    xaxis_title=\"Time (s)\",\n",
    "    yaxis_title=\"Amplitude\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"avg amplitude: \", np.average(peaks_y)) \n",
    "print(\"noise level (std / A): \", np.std(signal)/np.average(peaks_y)) # slightly over overestimated given that amplitudes were not removed from calculation\n",
    "print(0.005854308082561044^2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peak_amplitudes = [signal[i] for i in peaks_found]\n",
    "\n",
    "# Number of bins for the histogram\n",
    "num_bins = 10\n",
    "\n",
    "# Create histogram\n",
    "plt.hist(peak_amplitudes, bins=num_bins, color='blue', alpha=0.7)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Peak Amplitudes')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of Peak Amplitudes')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Applying peaks of roi_butterfilt_zscore_gaussian but plotting spikes from roi_butterfilt\n",
    "\n",
    "import numpy as np\n",
    "from scipy.signal import find_peaks\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "signal = roi_butterfilt_zscore_gaussian.copy()\n",
    "# signal = roi_butterfilt.copy() # For nikolai, removed zscore and gaussian \n",
    "\n",
    "z_threshold = 5\n",
    "window_sec = 0.5\n",
    "peaks = find_peaks_zscore(signal.copy(), window_sec, z_threshold) \n",
    "\n",
    "x = np.arange(len(signal))\n",
    "# y = roi_butterfilt  # We have the option of \"applying\" peaks to the roi_butterfilt (more raw) rather than roi_butterfilt_zscore_gaussian\n",
    "# the small difference is that amplitude of average trace went down .5, which is bad because it's harder to detect.\n",
    "y = signal  \n",
    "peak_amplitudes = y[peaks]\n",
    "\n",
    "# Determine the percent thresholds for peaks\n",
    "threshold_low = np.percentile(peak_amplitudes, 85) \n",
    "threshold_high = np.percentile(peak_amplitudes, 90)\n",
    "\n",
    "# Filter peaks within the specified range\n",
    "selected_peaks = [peaks[i] for i in range(len(peaks)) if threshold_low <= peak_amplitudes[i] <= threshold_high]\n",
    "print(\"n_peaks: \", len(peaks))\n",
    "print('n_selected_peaks: ', len(selected_peaks))\n",
    "# Length of segments before and after the peak\n",
    "segment_length_before = 50 # 150 for Jedi, 50 for Force1a\n",
    "segment_length_after = 70 # 250 for Jedi, 70 for Force1a\n",
    "\n",
    "\n",
    "\n",
    "# List to store segments\n",
    "segments = []\n",
    "\n",
    "# Create segments around each selected peak\n",
    "for peak in selected_peaks:\n",
    "    # Ensure the peak is not near the edges of the signal\n",
    "    if peak - segment_length_before >= 0 and peak + segment_length_after < len(signal):\n",
    "        # Extract segment around the peak\n",
    "        segment = signal[peak - segment_length_before : peak + segment_length_after + 1]\n",
    "        segments.append(segment)\n",
    "\n",
    "# Calculate the average trace from the segments\n",
    "average_trace = np.mean(segments, axis=0)\n",
    "\n",
    "# Convert x-axis ticks to represent secperframe\n",
    "x_ticks_sec = np.arange(-segment_length_before * secperframe*1000, (segment_length_after + 1) * secperframe*1000, step=secperframe*1000)\n",
    "x_ticks_labels = [f'{tick:.2f}' for tick in x_ticks_sec]\n",
    "\n",
    "# Visualize the segments and the average trace\n",
    "plt.figure(figsize=(5, 6))\n",
    "for segment in segments:\n",
    "    plt.plot(segment, color='blue', alpha=0.3)  # Individual segments in blue with transparency\n",
    "plt.plot(average_trace, color='red', linewidth=2, label='Average Trace')  # Average trace in red\n",
    "plt.axvline(x=segment_length_before, color='gray', linestyle='--', linewidth=0.5)  # Vertical line at time zero\n",
    "plt.axhline(y=0, color='gray', linestyle='--', linewidth=0.5)  # Horizontal line at amplitude zero\n",
    "plt.xlabel('Time (ms)')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.title('Selected Peaks, with average')\n",
    "# plt.xticks(ticks=np.arange(0, len(average_trace), step=50), labels=x_ticks_labels[::50])  # for Jedi\n",
    "plt.xticks(ticks=np.arange(0, len(average_trace), step=10), labels=x_ticks_labels[::10], fontsize=8, rotation='vertical')  # for Force1a\n",
    "\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle=':', linewidth=0.5, color='gray')  # Add gridlines for better readability\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Here, the plot is updated so that the amplitude is based on a local baseline rather than simply 0.  \n",
    "###  But difference seems negligible  \n",
    "\n",
    "import numpy as np\n",
    "from scipy.signal import find_peaks\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "signal = roi_butterfilt_zscore_gaussian.copy()\n",
    "\n",
    "z_threshold = 4\n",
    "window_sec = 0.5\n",
    "peaks = find_peaks_zscore(signal.copy(), window_sec, z_threshold) \n",
    "\n",
    "x = np.arange(len(signal))\n",
    "y = roi_butterfilt_zscore_gaussian  # Here we want to apply the peaks from roi_butterfilt_zscore_gaussian to the original signal\n",
    "peak_amplitudes = []\n",
    "\n",
    "# Length of segments before and after the peak\n",
    "segment_length_before = 150\n",
    "segment_length_after = 250\n",
    "\n",
    "# The amplitude is based on a local baseline \n",
    "# local baseline = average of a segment (length = baseline window) of the signal preceding (distance = tau_rise) the peak\n",
    "tau_rise_sec = .01 # visual estimate from plot \n",
    "tau_rise = int(tau_rise_sec * framespersec)\n",
    "baseline_window_sec = .03 # villette used 0.0003, which seems very short. \n",
    "baseline_window = int(baseline_window_sec * framespersec)\n",
    "\n",
    "# Create segments around each selected peak\n",
    "for peak in peaks:\n",
    "    # Ensure the peak is not near the edges of the signal\n",
    "    if peak - baseline_window >= 0 and peak + segment_length_after < len(signal):\n",
    "        # Extract segment before the peak\n",
    "        segment_before_peak = signal[peak - baseline_window - tau_rise : peak - tau_rise]\n",
    "        \n",
    "        # Calculate the average of the segment before the peak\n",
    "        average_before_peak = np.mean(segment_before_peak)\n",
    "        \n",
    "        # Calculate the peak amplitude as y[peak] - average_before_peak\n",
    "        peak_amplitude = y[peak] - average_before_peak\n",
    "        peak_amplitudes.append(peak_amplitude)\n",
    "\n",
    "# Determine the percent thresholds for peaks\n",
    "threshold_low = np.percentile(peak_amplitudes, 80)\n",
    "threshold_high = np.percentile(peak_amplitudes, 90)\n",
    "\n",
    "# Filter peaks within the specified range\n",
    "selected_peaks = [peaks[i] for i in range(len(peaks)) if threshold_low <= peak_amplitudes[i] <= threshold_high]\n",
    "print(\"n_peaks: \", len(peaks))\n",
    "print('n_selected_peaks: ', len(selected_peaks))\n",
    "\n",
    "# List to store segments\n",
    "segments = []\n",
    "\n",
    "# Create segments around each selected peak\n",
    "for peak in selected_peaks:\n",
    "    # Ensure the peak is not near the edges of the signal\n",
    "    if peak - segment_length_before >= 0 and peak + segment_length_after < len(signal):\n",
    "        # Extract segment around the peak\n",
    "        segment = signal[peak - segment_length_before : peak + segment_length_after + 1]\n",
    "        segments.append(segment)\n",
    "\n",
    "# Calculate the average trace from the segments\n",
    "average_trace = np.mean(segments, axis=0)\n",
    "\n",
    "# Convert x-axis ticks to represent secperframe\n",
    "x_ticks_sec = np.arange(-segment_length_before * secperframe, (segment_length_after + 1) * secperframe, step=secperframe)\n",
    "x_ticks_labels = [f'{tick:.2f}' for tick in x_ticks_sec]\n",
    "\n",
    "# Visualize the segments and the average trace\n",
    "plt.figure(figsize=(5, 6))\n",
    "for segment in segments:\n",
    "    plt.plot(segment, color='blue', alpha=0.3)  # Individual segments in blue with transparency\n",
    "plt.plot(average_trace, color='red', linewidth=2, label='Average Trace')  # Average trace in red\n",
    "plt.axvline(x=segment_length_before, color='gray', linestyle='--', linewidth=0.5)  # Vertical line at time zero\n",
    "plt.axhline(y=0, color='gray', linestyle='--', linewidth=0.5)  # Horizontal line at amplitude zero\n",
    "plt.xlabel('Time (seconds)')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.title('Selected Peaks FROM ROI, with local baseline')\n",
    "plt.xticks(ticks=np.arange(0, len(average_trace), step=50), labels=x_ticks_labels[::50])  # Adjust ticks and labels\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle=':', linewidth=0.5, color='gray')  # Add gridlines for better readability\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "\n",
    "# mls_bfilt_zscr_gaus = roi_butterfilt_zscore_gaussian.reshape((1, -1))\n",
    "# # np.save(\"C:/Users/huynh/INT/karthala/cascade/dFFv.npy\",dFFv)\n",
    "# scipy.io.savemat(\"C:/Users/huynh/INT/karthala/mls_bfilt_zscr_gaus.mat\", {'mls_bfilt_zscr_gaus': mls_bfilt_zscr_gaus})\n",
    "\n",
    "\n",
    "# alberto_mls_bfilt_zscr_gaus = roi_butterfilt_zscore_gaussian.reshape((1, -1))\n",
    "# scipy.io.savemat(\"C:/Users/huynh/INT/karthala/alberto_mls_bfilt_zscr_gaus.mat\", {'alberto_mls_bfilt_zscr_gaus': alberto_mls_bfilt_zscr_gaus})\n",
    "\n",
    "nikolai_mlspk_bfilt_zscr_gaus = roi_butterfilt_zscore_gaussian.reshape((1, -1))\n",
    "scipy.io.savemat(\"C:/Users/huynh/INT/karthala/nikolai_mlspk_bfilt_zscr_gaus.mat\", {'nikolai_mlspk_bfilt_zscr_gaus': nikolai_mlspk_bfilt_zscr_gaus})\n",
    "\n",
    "nikolai_mlspk_bfilt = roi_butterfilt.reshape((1, -1))\n",
    "scipy.io.savemat(\"C:/Users/huynh/INT/karthala/nikolai_mlspk_bfilt.mat\", {'nikolai_mlspk_bfilt': nikolai_mlspk_bfilt})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roi_butterfilt_zscore_gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('C:/Users/huynh/INT/karthala/nikolai_s2p_bfilt_zscr_gaus.npy', roi_butterfilt_zscore_gaussian)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
